<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
    <meta name="viewport" content="Leaving Certificate Computer Science Project"/>
    <meta name="author" content="Ruairi"/>
    <link rel="stylesheet" href="CSS for LC.css" />

    <title>Leaving Cert Computer Science Project</title>
    </head>


<body>
    <header>
        <div class="header">
            <br>
            <br>
            <div class = "title">
                Leaving Cert Computer Science Project
            </div>
            <div style = "color:white; text-align: center; font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; font-size: 18px;">
                <h4>Examination Number: 102733</h4>
            </div>
        </div>
    </header>
<div class = "maindiv">    
    <div>
        <br>
        <br>
        <a id = "Top"><h2>Table of Contents</h2></a>
        <table>
            <tr><td class = "linkbig"><a href="#rationale">A Rationale Approach to The Brief</a></td></tr>
            <tr><td class = "linksmall"><a href="#research">Research</a></td></tr>
            <tr><td class = "linksmall"><a href="#response">Response</a></td></tr>
            <tr><td class = "linkbig"><a href="#video">The Artefact in Operation</a></td></tr>
            <tr><td class = "linkbig"><a href="#iterative">The Iterative Design Process</a></td></tr>
            <tr><td class = "linksmall"><a href="#investigate">Investigate</a></td></tr>
            <tr><td class = "linksmall"><a href="#design">Design</a></td></tr>
            <tr><td class = "linksmall"><a href="#create">Create</a></td></tr>
            <tr><td class = "linksmall"><a href="#evaluate">Evaluate</a></td></tr>
            <tr><td class = "linksmall"><a href="#document">Document</a></td></tr>
            <tr><td class = "linkbig"><a href="#development">Development of the Artefact</a></td></tr>
            <tr><td class = "linksmall"><a href="#overall">Overall Design</a></td></tr>
            <tr><td class = "linksmall"><a href="#developed">How It Was Developed</a></td></tr>
            <tr><td class = "linksmall"><a href="#considerations">Social and Ethical Considerations</a></td></tr>
            <tr><td class = "linksmall"><a href="#testing">Testing</a></td></tr>
            <tr><td class = "linksmall"><a href="#problems">Problems I Faced</a></td></tr>
            <tr><td class = "linkbig"><a href="#evaluation">Evaluation of the Artefact</a></td></tr>
            <tr><td class = "linksmall"><a href="#reflection">Reflection on Meeting The Brief</a></td></tr>
            <tr><td class = "linksmall"><a href="#future">Future Development of The Artefact</a></td></tr>
            <tr><td class = "linkbig"><a href="#network">Network Diagram</a></td></tr>
            <tr><td class = "linkbig"><a href="#flowchart">Flowchart of Artefact</a></td></tr>
            <tr><td class = "linkbig"><a href="#graph">Graph of Data</a></td></tr>
            <tr><td class = "linkbig"><a href="#references">References</a></td></tr>
            <tr><td class = "linkbig"><a href="#wordcount">Word Count</a></td></tr>
        </table>
    </div>
    <br>
    <div>
        <p class="brief">
            Project Brief: Create an innovative computational artefact which you feel could be used to address any or some 
            of the issues raised in the context of this brief and report on the work and process involved
        </p>
        <span><a id = "rationale"><h1>Approach to the Brief</h1></a><a class = "toplink" href = "#top">[Top]</a></span>
        <span><a id = "research"><h3>Research</h3></a></span>
        <p class = small style = "vertical-align: middle;">
            The first thing I did was review the web pages linked in the brief <sup class = references><a href = "#2">[2]</a></sup>. From these, I identified “Shopping Safely” as 
            an area to examine in more detail with a view to creating a project.
            <ul class = small>
                <li>There are many existing systems in shops to minimize the risk of spreading Covid-19, for example queue management systems,
                     signs to remind people to wear masks and automated hand sanitizer dispensers.</li>
                <li>Queue management systems work by using sensors to detect when a person enters or leaves the shop and allows the shop to 
                    monitor and limit the number of customers in the shop.</li>
                <li>Automated hand sanitizer dispensers. These dispense a small amount of hand sanitizer when a sensor is activated by a customer’s hand.</li>
                <li>Signs in shops remind people to wear a face covering.</li>
                <li>Using only signs to remind people to wear a face covering, may not be 100% effective due to customers not noticing the signs, or 
                    customers not adhering to the signs. This could be improved by using a system that detects if a customer is wearing a mask.</li>
                </ul>
        </p>
    </div>
    <div>
        <br>
        <span><a class = "toplink" href = "#top">[Top]</a><a id = "response"><h3>Response to the Brief</h3></a></span>
        <p class = small>
            <ul class = small>
                <li>I thought of building a queue management system using passive infrared sensors to detect people entering and exiting a building by installing these sensors at the entry and exit.</li>
                <li>I also thought of creating a system that would use a camera to determine whether or not a person was wearing a mask.</li>
                <li>I decided not to create a queue management system as I have already seen a system like this in many shops.</li>
                <li>I decided to build an artefact that was made up of a camera, a computer, and LEDs that determines whether a person is wearing a mask.
                     This project resonates with me more as I have never seen one in use before.</li>
                <li>The aim of the system is to ensure people are wearing a mask in a building that does not have a supervised entrance.</li>
                <li>The potential end-users are covid officers in schools and shops, but users may also be thought to include the students or customers.</li>
            </ul>
        </p>
    </div>
    <div>
        <br>
        <span><a class = "toplink" href = "#top">[Top]</a><a id = "video"><h1>The Artefact in Operation</h1></span>
        <video width="320" height="240" controls>
            <source src="Video For Artefact.mp4" type="video/mp4">
        </video>
    </div>
    <div>
    <br>
    <span><a id = "iterative"><h1>The Iterative Design Process</h1></a><a class = "toplink" href = "#top">[Top]</a></span>
    <span><h3>Investigate</h3></span>
    <p class = small>
        <ul class = small>
            <li>From the brief, the problem I decided to solve was detecting if someone entering a building 
                was wearing a face mask or not, with feedback to the user in the form of a red or green light.</li>
            <li>I decided to record the information in a csv file and to display it in real-time on a graph,
                on a screen, where it can be monitored by the building Covid officer.</li>
        </ul>
    </p>
    <br>
    <span><a class = "toplink" href = "#top">[Top]</a><a id = "plan"></a><h3>Plan</h3></a></span>
    <p class = small>
        <ul class = small>
            <li>From my understanding of the problem, I decided to use both microbit and raspberry pi technology to implement the solution.</li>
            <li>I needed to use raspberry pi because face recognition software was not available on the microbit.</li>
            <li>Part of the design brief required that the client system communicates to a central remote data collection point, so I decided to use two microbits communicating wirelessly.</li>
        </ul>
    </p>
    <br>
    <span><a class = "toplink" href = "#top">[Top]</a><a id = "design"><h3>Design</h3></a></span>
    <p class = "small">
        <ul class = small>
            <li>I used elements of both a waterfall and agile approach in that I had an overall view of the end product, however I developed it in stages, 
                getting each stage working before developing the next stage and modifying previous steps as required.</li>
            <li>The plan was that on the press of a button, a camera would take a picture of the person, then run 
                it through face recognition software on a raspberry pi, and detect if a user was wearing a mask. </li>
            <li>If the user was wearing a mask a green LED would flash to allow entry, otherwise a red LED would flash.</li>
            <li>As I needed to send the data to a remote data collection point, I decided to use two microbits communicating wirelessly (range approx. 70m), 
                with the raspberry pi connecting serially to the first microbit, and the second microbit connecting serially to a laptop to store the information in a csv.</li>
            <li>One consideration was the camera should not be running continuously due to privacy issues.  I decided to take a single photograph, 
                triggered by the user placing their two hands over two sensors, and analyse that for the presence of a mask.</li>
            <li>My initial attempt to use face recognition software, to detect someone wearing a mask, was using a python library called OpenCV.
                <sup class = references><a href = "#3">[3]</a></sup>
                This library uses machine learning for computer vision and image processing. I found it would need a very large number of sample photos, 
                including all skin colours and sexes, etc., to ‘teach’ the system.</li>
            <li>Because of the teaching and learning requirement needed by OpenCV, I continued looking for other python face detection 
                libraries that needed less training. I found a library called “face-recognition” 
                <sup class = references><a href = "#4">[4]</a></sup>
                that already includes data in the library and 
                can detect a face in an image. I tested this library and found that it reliably detected a face if a person wasn’t wearing a mask, 
                but never detected a face if a person was wearing a mask. Because of this, I decided to simply use the presence of a face in a photograph 
                to mean there was no mask.</li>
                <li><a href = "#flowchart" style = "color:blue">Click here for Flowchart.</a></li>
        
        </ul>
    </p>
    <br>
    <span><a class = "toplink" href = "#top">[Top]</a><a id = "create"><h3>Create</h3></a></span>
    <p>
        <ul class = small>
            <li>I implemented the system using one raspberry pi + camera, two BBC microbits, and a windows 10 laptop acting as the remote data collection point.</li>
            <li>I first used a standard USB webcam attached to the raspberry pi, but the image quality was poor, and the colours were distorted. 
                I then obtained a raspberry pi camera which greatly improved the image quality. </li>
            <li>The final design uses a python program on the raspberry pi to take a picture of the user on the push of two buttons,
                 and saves it to a designated folder on the raspberry pi. The python program then uses the face-recognition library
                 <sup class = "references"><a href = "#4">[4]</a></sup>
                 to analyse 
                 the photo for the presence of a face. The program sends ‘nomask’ / ‘mask’ to microbit 1 depending on whether there is a face present or not.</li>
            <li>Microbit 1 then sends a 1 or 0 (1 = mask) wirelessly to microbit 2.</li>
            <li>Microbit 2 passes the value serially to a python program running on a laptop.</li>
            <li>The python program saves the value to a csv file, and then updates a graph with the contents of the csv file.</li>
        </ul>
    </p>
    <br>
    <span><a class = "toplink" href = "#top">[Top]</a><a id = "evaluate"><h3>Evaluate</h3></a></span>
    <p>
        <ul class = small>
            <li>One issue I found was that the photograph was being left on the raspberry pi after the program ends, 
                so I added a line of code
                <sup class = "references"><a href = "#5">[5]</a></sup>
                to delete the image after analysis to avoid any privacy issues.</li>
            <li>Everything worked as intended but if this were to be used commercially, I would use sensors instead of switches, 
                so users didn’t have to touch anything (and risk contracting Covid-19).</li>
        </ul>
    </p>
    <br>
    <span><a class = "toplink" href = "#top">[Top]</a><a id = "document"><h3>Document</h3></a></span>
    <p>
        <ul class = small>
            <li>I found the iterative design process to be effective. </li>
            <li>I investigated and understood the problem, planned my approach, and designed and created an initial working artefact. 
                I evaluated the results, changed anything that needed changing and developed the next part. I then repeatedly iterated this process.</li>
        </ul>
    </p>
    <br>
    <span><a id = "development"><h1>Development of the Artefact</h1></a><a class = "toplink" href = "#top">[Top]</a></span>
    <span><a id = "overall"><h3>Overall Design</h3></a></span>
    <p>
        <ul class = small>
            <li>The overall architecture of this system is a raspberry pi 4, with a pi camera. A photo is taken on the press of two push switches. </li>
            <li>A python program loops, waiting for the press of these buttons. Once pressed a picture is taken and analysed using a python library called face-recognition.</li>
            <li>If the library detects a face in the picture, it means the person cannot be wearing a mask, so it sends the string “nomask” serially to a microbit (or “mask” if no face is found). </li>
            <li>The microbit then displays a red or green LED, depending on the received string. It then sends the value (1 = mask, or 0 = no mask) via radio signal to another microbit.</li>
            <li>The second microbit sends the value to a python program on a laptop, where it is written to a csv file, and displayed on a real-time graph on the laptop screen.</li>
            <li><a href = "#network" style = "color:blue">Click here for network diagram.</a></li>
        </ul>
    </p>
    <br>
    <span><a class = "toplink" href = "#top">[Top]</a><a id = "developed"><h3>How It Was Developed</h3></a></span>
    <p>
        <ul class = small>
            <li>The first thing I did was set up a raspberry pi and download python 3, and the IDE ‘Thonny’. I looked at tutorials online to set up the raspberry pi as I had never used one before.</li>
            <li>I then researched face recognition software. For privacy / GDPR reasons I decided to use a system that would take pictures instead of continuous video.</li>
            <li>I wrote a python program on the raspberry pi and used the python library "picamera"
                <sup class = "references"><a href = "#6">[6]</a></sup>
                 to capture photos from the camera.</li>
            <li>The python program runs on start-up of the raspberry pi
                <sup class = "references"><a href = "#7">[7]</a></sup>
                , and ends when the raspberry pi gets turned off, with the data being saved on a laptop throughout the running of the program. 
                I used an infinite ‘while True:’ loop which waited for two switches to be pressed before capturing the image.</li>
            <li>I then use the python library "face-recognition"
                <sup class = "references"><a href = "#4">[4]</a></sup>
                 to check the image for the presence of a face.</li>
            <li>I needed to then send this information to a central data collection point, that a covid officer could monitor.</li>
            <li>I researched to see if the raspberry pi could communicate wirelessly with the microbit, but the only solutions I found required a 
                vast knowledge of the raspberry pi and many lines of code.
                <sup class = "references"><a href = "#8">[8]</a></sup></li>
            <li>I then thought of using two microbits to communicate the information. This was a great solution to my problem as the raspberry pi can write to the 
                microbit serially within the python program, and it was not complicated to do. On the laptop side, a python program receives the data serially 
                from the microbit in the same way. I used makecode editor to program the microbits
                <sup class = "references"><a href = "#9">[9]</a></sup>
                and used Keith Quille’s book to learn how to connect them serially.
                <sup class = "references"><a href = "#1">[1]</a></sup></li>
            <li>The python program on the laptop writes the received value (1 or 0) to a csv file. It then reads this file, and draws a graph with a green line for 
                masks, and a red line for no-mask. It also updates in real-time (as seen in video) by using a while loop for every time data is received serially. 
                I used the python library “matplotlib” 
                <sup class = "references"><a href = "#10">[10]</a><a href = "#1">[1]</a></sup>
                to create the graph.</li>
        </ul>
    </p>
    <br>
    <span><a class = "toplink" href = "#top">[Top]</a><a id = "consideration"><h3>Social and Ethical Considerations</h3></a></span>
    <p>
        <ul class = small>
            <li>The first consideration I thought of was privacy issues of recording people. For this reason, I designed the system, so the user gave permission by using switches.</li>
            <li>The second consideration I needed to be aware of was saving the pictures which again would cause privacy issues. My first solution was to overwrite the previous 
                image when the next image was taken. However, that still left one image on the system when the system was turned off. To solve this issue, I then added a line 
                of code to delete the image after face recognition analysis.<sup class = "references"><a href = "#5">[5]</a></sup></li>
            <li>Another consideration I had was people covering their faces with their hands instead of wearing a mask. I solved this by adding two push switches, positioned far 
                enough away from each other, so that a person would have to use two hands to take the picture. </li>
            <li>Another consideration is that in commercial use, a light dependant sensor would be more suitable so the user wouldn’t have to touch anything and risk contracting Covid-19.</li>
        </ul>
    </p>
    <br>
    <span><a class = "toplink" href = "#top">[Top]</a><a id = "testing"><h3>Testing</h3></a></span>
    <p>
        <ul class = small>
            <li>After developing each stage, I tested it, fixed any issues, and made sure it was working before, going on to the next stage. I repeated this process as I added each stage.</li>
            <li>I tested the system on different people in my class, and it proved very reliable at recognizing all the different faces.</li>
            <li>I wrote a python program to send strings serially to the microbit, from the raspberry pi, so I could test without the camera.</li>
            <li>I also wrote a microbit program that would send information wirelessly on the press of a button so that I could test the two microbits communicating.<sup class = "references"><a href = "#1">[1]</a></sup></li>
        </ul>
    </p>
    <br>
    <span><a class = "toplink" href = "#top">[Top]</a><a id = "problems"><h3>Problems I Faced</h3></a></span>
    <p>
        <ul class = small>
            <li>I needed a way of connecting the raspberry pi to a microbit but the only possible way of doing it wirelessly was extremely difficult and time consuming.
                <sup class = "references"><a href = "#8">[8]</a></sup> 
                I decided to connect a microbit serially and send data wirelessly from the first one to another one.</li>
            <li>When I was writing from the raspberry pi to the microbit, I first struggled to find the serial port that I had to open, I found a website 
                <sup class = "references"><a href = "#11">[11]</a></sup>
                that instructed 
                me how to find the port and it worked.</li>
            <li>I also had a problem writing a string to the microbit, every time I would write it, nothing would be sent. After some research I found a website that said 
                that you must end the string with ‘\n’ for it to be sent serially.
                <sup class = "references"><a href = "#12">[12]</a></sup></li>
            <li>At first, I was using a USB webcam, but the image quality was poor and colours were distorted so I obtained a raspberry pi camera and it worked perfectly</li>
            <li>When I was writing the code to draw the graph in real time, the code would stop every time the graph window opened and waited for it to close to continue. 
                I found a website
                <sup class = "references"><a href = "#13">[13]</a></sup> 
                that showed me how to bypass this by using the function ‘draw()’ instead of ‘show()’.</li>
        </ul>
    </p>
    <br>
    <span><a id = "evaluation"><h1>Evaluation of The Artefact</h1></a><a class = "toplink" href = "#top">[Top]</a></span>
    <span><a id = "reflection"><h3>Reflection on Meeting The Brief</h3></a></span>
    <p>
        <ul class = small>
            <li>The finished artefact was very close to my original design. I achieved all my design ambitions.</li>
            <ol>
                <li>The system accepts analogue inputs, an image, and a button press. These inputs are converted from analogue to digital, using a camera, and a button.</li>
                <li>I incorporated an interactive user interface by using push switches. The system is completely automated. Once the switches are pushed it runs the program without any manual intervention.</li>
                <li>The analysis component was a real-time graph that changes on each button press, allowing a user to monitor the data in real-time.</li>
                <li>I used a laptop as the remote data collection point, and a raspberry pi as a client. The raspberry pi sends a Boolean value to the laptop.</li>
                <li>The system uses a csv file to store information on the laptop for further analysis.</li>
                <li>A python program updates a graph on a laptop screen, with data for decision making purposes and allowing an evaluation of the hypothesis: the majority of people entering are wearing masks.</li>
            </ol>
            <li>The needs of the envisaged users were met. People entering the building have an easy-to-use system. The covid officer has a clear picture of the data.</li>
        </ul>
    </p>
    <br>
    <span><a class = "toplink" href = "#top">[Top]</a><a id = "future"><h3>Future Development of the Artefact</h3></a></span>
    <p>
        <ul class = small>
            <li>My artefact could be improved by using passive infrared sensors, or light dependant resistors, instead of buttons, so that the users would not have to touch anything, 
                and so avoid the risk of contracting or spreading Covid-19.</li>
            <li>Another possible improvement would be to replace the LEDs with red/green traffic lights, which would be clearly visible to the person entering the building.</li>
            <li>The artefact could also be interconnected with a barrier, or turnstile, that would only open when a person was wearing a mask. This might be useful for supporters 
                entering a stadium or a concert.</li>
            <li>Another possible application of this artefact could be banks or workplaces where people are not allowed to enter when wearing motorcycle helmets, or other face coverings. 
                The system could provide a silent alarm to personnel in the bank or workplace if someone tried to enter wearing a helmet, and it could also prevent the door from unlocking.</li>
        </ul>
    </p>
    <br>
    <br>
    <span><a class = "toplink" href = "#top">[Top]</a><a id = "network"><h3>Network Diagram</h3></a></span>
    <img height = "350" src="Network Diagram CS.jpeg" alt="Network Diagram"/>
    <br>
    <br>
    <br>
    <span><a class = "toplink" href = "#top">[Top]</a><a id = "flowchart"><h3>Flowchart</h3></a></span>
    <img height = "450" src="Flowchart CS.png" alt="Flowchart"/>
    <br>
    <br>
    <br>
    <br>
    <br>
    <span><a class = "toplink" href = "#top">[Top]</a><a id = "graph"><h3>Graph of Sample Data</h3></a></span>
    <p class = "small">
        This is a screenshot of the graph that appears on the laptop and it displays sample data that I collected.
    </p>
    <img height = "450" src="Data Graph.png" alt="Flowchart"/>
    <br>
    <br>
    <br>
    <br>
    <br>
    <span><a id = "references"><h3>References</h3></a><a class = "toplink" href = "#top">[Top]</a></span>
    <p>
        <a id = "references"><ol class = links></a>
            <li>Computer Science for Leaving Certificate - Textbook by Brett A. Becker & Keith Quille</li>
            <li><a id = "2" href="https://www2.hse.ie/coronavirus/">https://www2.hse.ie/coronavirus/</a></li>
            <li><a id = "3" href="https://realpython.com/face-recognition-with-python/">https://realpython.com/face-recognition-with-python/</a></li>
            <li><a id = "4" href="https://pypi.org/project/face-recognition/">https://pypi.org/project/face-recognition/</a></li>
            <li><a id = "5" href="https://www.oreilly.com/library/view/python-programming-with/9781786467577/fe36c270-4e19-4162-a620-f0e462bdfece.xhtml">https://www.oreilly.com/library/view/python-programming-with/9781786467577/fe36c270-4e19-4162-a620-f0e462bdfece.xhtml</a></li>
            <li><a id = "6" href="https://projects.raspberrypi.org/en/projects/getting-started-with-picamera/6">https://projects.raspberrypi.org/en/projects/getting-started-with-picamera/6</a></li>
            <li><a id = "7" href="https://www.raspberrypi-spy.co.uk/2015/02/how-to-autorun-a-python-script-on-raspberry-pi-boot/">https://www.raspberrypi-spy.co.uk/2015/02/how-to-autorun-a-python-script-on-raspberry-pi-boot/</a></li>
            <li><a id = "8" href="https://www.raspberrypi.org/forums/viewtopic.php?t=232392">https://www.raspberrypi.org/forums/viewtopic.php?t=232392</a></li>
            <li><a id = "9" href="https://makecode.microbit.org/">https://makecode.microbit.org/</a></li>
            <li><a id = "10" href="https://matplotlib.org/2.0.2/users/pyplot_tutorial.html">https://matplotlib.org/2.0.2/users/pyplot_tutorial.html</a></li>
            <li><a id = "11" href="https://www.raspberrypi.org/forums/viewtopic.php?t=31141">https://www.raspberrypi.org/forums/viewtopic.php?t=31141</a></li>
            <li><a id = "12" href="https://pyserial.readthedocs.io/en/latest/shortintro.html">https://pyserial.readthedocs.io/en/latest/shortintro.html</a></li>
            <li><a id = "13" href="https://stackoverflow.com/questions/28269157/plotting-in-a-non-blocking-way-with-matplotlib">https://stackoverflow.com/questions/28269157/plotting-in-a-non-blocking-way-with-matplotlib</a></li>
        </ol>
    </p>
    <br>
    <br>
    <br>
    <span><a id = "wordcount"><h3>Word Count</h3></a><a class = "toplink" href = "#top">[Top]</a></span>
    <br>
    <br>
    <table class = "wordcount" border = "1" >
        <tr>
            <td>Section</td><td>Word Count</td>
        </tr><tr>
            <td>1.1 Research</td><td>177</td>
        </tr><tr>
            <td>1.2 Response to the brief</td><td>159</td>
        </tr><tr>
            <td>3.1 The iterative design process</td><td>789</td>
        </tr><tr>
            <td>3.2 Development of the artefact</td><td>997</td>
        </tr><tr>
            <td>4.1 Reflection on meeting the brief</td><td>198</td>
        </tr><tr>
            <td>4.2 Future deveelopment of the artefact</td><td>156</td>
        </tr><tr>
            <td>Total:</td><td>2,476</td>
        </tr>
    </table>

</div>








    </br>
    </br>
</div>
</body>

<footer>
</footer>

</html>